{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanjidh090/kaggle_colab_practise/blob/main/Copy_of_Deep_Learning_Emotion_Recognition_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfRpRW1SuBw"
      },
      "source": [
        "# Deep Learning Based Emotion Recognition with PyTorch\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/emotion_classifier.png?raw=true)\n",
        "\n",
        "In this notebook we are going to learn how to train deep neural networks, such as recurrent neural networks (RNNs), for addressing a natural language task known as **emotion recognition**. We will cover everything you need to know to get started with NLP using deep learning frameworks such as TensorFlow. We will cover the common best practices, functionalities, and steps you need to understand the basics of TensorFlow APIs to build powerful predictive models via the computation graph. In the process of building our models, we will compare PyTorch and TensorFlow to let the learner appreciate the strenghts of each tool.\n",
        "\n",
        "by [Elvis Saravia](https://twitter.com/omarsar0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkM141cSuBz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrz3-nSrSuB1"
      },
      "source": [
        "## Outline\n",
        "1. Deep Learning Frameworks\n",
        "     - 1.1 Eager execution\n",
        "     - 1.2 Computation graph\n",
        "2. Tensors\n",
        "    - 2.1 Basic math with tensors\n",
        "    - 2.2 Transforming tensors\n",
        "3. Data\n",
        "    - 3.1 Preprocessing data\n",
        "        - Tokenization and Sampling\n",
        "        - Constructing Vocabulary and Index-Word Mapping\n",
        "    - 3.2 Converting data into tensors\n",
        "    - 3.3 Padding data\n",
        "    - 3.4 Binarization\n",
        "    - 3.5 Split data\n",
        "    - 3.6 Data Loader\n",
        "4. Model\n",
        "    - 4.1 Pretesting Model\n",
        "    - 4.2 Testing models with eager execution\n",
        "5. Training\n",
        "6. Evaluation on Testing Dataset\n",
        "    - 6.1 Confusion matrix\n",
        "- Final Words\n",
        "- References\n",
        "- *Storing models and setting checkpoints (Exercise)*\n",
        "- *Restoring models (Exercise)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9JWaqqSuB1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCbWgC0tSuB3"
      },
      "source": [
        "## 1. Deep Learning Frameworks\n",
        "There are many deep learning frameworks such as Chainer, DyNet, MXNet, PyTorch, TensorFlow, and Keras. Each framework has their own strenghts which a researcher or a developer may want to consider before choosing the right framework. In my opinion, PyTorch is great for researchers and offers eager execution by default, but its high-level APIs require some understanding of deep learning concepts such as **affine layers** and **automatic differentiation**. On the other hand, TensorFlow was originally built as a low-level API that provides a robust list of functionalities to build deep learning models from the ground up. More recently, TensorFlow also offers **eager execution** and is equipped with a high-level API known as Keras.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/dl_frameworks.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv8DnrQSuB5"
      },
      "source": [
        "### 1.1 Eager Execution\n",
        "Eager execution allows us to operate on the computation graph dynamically, also known as **imperative programming**. TensorFlow requires that you manually set this mode, while PyTorch comes with this mode by default. Below we import the necessary libraries to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9db0b53-88ac-4f53-deca-63cd806f2ee8"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: torch-0.4.1-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6"
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK69ztCKSuB-"
      },
      "source": [
        "### 1.2 Computation Graph\n",
        "A simplified definition of a neural network is a string of functions that are **differentiable** and that we can combine together to get more complicated functions. An intuitive way to express this process is through computation graphs.\n",
        "\n",
        "![alt txt](http://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png)\n",
        "\n",
        "Image credit: [Chris Olah](http://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6243JBwQSuB_"
      },
      "source": [
        "## 2. Tensors\n",
        "Tensors are the fundamental data structure used to store data that will be fed as input to a computation graph for processing and applying tranformations. Let's create two tensors and multiply them, and then output the result. The figure below shows a 4-D Tensor.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7863cecf-036d-41dc-c5e5-b5beeba2538c"
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 3.],\n",
            "        [3., 7.]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTM0Y6hSuCF"
      },
      "source": [
        "### 2.1 Math with Tensors\n",
        "PyTorch and other deep learning libraries like TensorFlow allow you to do **automatic differentation**. Let's try to compute the derivative of a function -- in this case that function is stored in the variable `z`. In PyTorch, the option `requires_grad=True` tracks all operations applied to the input tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e612459-6513-4eca-b991-c269f06c3cdd"
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHvtrCLSuCK"
      },
      "source": [
        "You can verfiy the output with the equations in the figure below:\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/autograd.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL"
      },
      "source": [
        "### 2.2 Transforming Tensors\n",
        "We can also apply some transformation to a tensor such as adding a dimension or transposing it. Let's try both adding a dimension and transposing a matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36e938e-859e-4415-fbd2-7affda283d01"
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size())\n",
        "\n",
        "# transpose\n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape:  torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP"
      },
      "source": [
        "## 3. Emotion Dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCiiFsBNbuD"
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliFaijvNfIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b61a0de-ec38-44ee-8a18-38ad0f5edc68"
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2qHNv2-N9BC"
      },
      "source": [
        "We had already processed the data for you. You can find the pickle file [here](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/data/merged_training.pkl)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "15560da5-9020-4872-d904-1fd95dcb6f90"
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "data.sentiment.value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='sentiment'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f2277a1b-5679-4697-c51d-3e34c2b82f12"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                               text sentiment\n",
              "0   0  ব্যাংকের কর্মীরা অত্যন্ত দক্ষ এবং সহযোগী। তাদে...  positive\n",
              "1   1  আমি কোম্পানির নতুন প্রোডাক্ট সম্পর্কে জানতে চা...   neutral\n",
              "2   2  কোম্পানির সেবা মানুষের টাকা নষ্ট করার জন্য। আম...  negative\n",
              "3   3  ব্যাংকের সিস্টেম প্রায়ই ডাউন থাকে। জরুরি সময়...  negative\n",
              "4   4  ব্যাংকের নোটিফিকেশন সিস্টেম কাজ করে না। আমি আম...  negative\n",
              "5   5  কোম্পানির প্রোডাক্ট কি অনলাইনে অর্ডার করা যায়...   neutral\n",
              "6   6  কোম্পানির অফার কি শুধু নতুন গ্রাহকদের জন্য? পু...   neutral\n",
              "7   7  ব্যাংকের ডকুমেন্টেশন প্রক্রিয়া অত্যন্ত জটিল। ...  negative\n",
              "8   8  ব্যাংকের সিডি সুবিধা আমাকে অতিরিক্ত আয় করতে স...  positive\n",
              "9   9  আমি কোম্পানির সার্ভিস নিয়ে খুবই সন্তুষ্ট। তাদ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d37637bf-dac1-4236-88a4-81aee1d081b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ব্যাংকের কর্মীরা অত্যন্ত দক্ষ এবং সহযোগী। তাদে...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>আমি কোম্পানির নতুন প্রোডাক্ট সম্পর্কে জানতে চা...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>কোম্পানির সেবা মানুষের টাকা নষ্ট করার জন্য। আম...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ব্যাংকের সিস্টেম প্রায়ই ডাউন থাকে। জরুরি সময়...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ব্যাংকের নোটিফিকেশন সিস্টেম কাজ করে না। আমি আম...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>কোম্পানির প্রোডাক্ট কি অনলাইনে অর্ডার করা যায়...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>কোম্পানির অফার কি শুধু নতুন গ্রাহকদের জন্য? পু...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>ব্যাংকের ডকুমেন্টেশন প্রক্রিয়া অত্যন্ত জটিল। ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>ব্যাংকের সিডি সুবিধা আমাকে অতিরিক্ত আয় করতে স...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>আমি কোম্পানির সার্ভিস নিয়ে খুবই সন্তুষ্ট। তাদ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d37637bf-dac1-4236-88a4-81aee1d081b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d37637bf-dac1-4236-88a4-81aee1d081b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d37637bf-dac1-4236-88a4-81aee1d081b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33b0af10-973f-4d73-83ac-c1b37b7be233\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33b0af10-973f-4d73-83ac-c1b37b7be233')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33b0af10-973f-4d73-83ac-c1b37b7be233 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 189,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 0,\n        \"max\": 188,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          184,\n          163,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 157,\n        \"samples\": [\n          \"\\u0995\\u09cb\\u09ae\\u09cd\\u09aa\\u09be\\u09a8\\u09bf\\u09b0 \\u0993\\u09af\\u09bc\\u09c7\\u09ac\\u09b8\\u09be\\u0987\\u099f \\u0996\\u09c1\\u09ac \\u09a6\\u09cd\\u09b0\\u09c1\\u09a4 \\u09b2\\u09cb\\u09a1 \\u09b9\\u09af\\u09bc \\u098f\\u09ac\\u0982 \\u09b8\\u09b9\\u099c\\u09c7 \\u09a8 \\u09c7\\u09ad\\u09bf\\u0997\\u09c7\\u099f \\u0995\\u09b0\\u09be \\u09af\\u09be\\u09af\\u09bc\\u0964 \\u099a\\u09ae\\u09ce\\u0995\\u09be\\u09b0 \\u0987\\u0989\\u099c\\u09be\\u09b0 \\u098f\\u0995\\u09cd\\u09b8\\u09aa\\u09c7\\u09b0\\u09bf\\u09af\\u09bc\\u09c7\\u09a8\\u09cd\\u09b8\\u0964\",\n          \"\\u09ac\\u09cd\\u09af\\u09be\\u0982\\u0995\\u09c7\\u09b0 \\u09b6\\u09be\\u0996\\u09be\\u09b0 \\u0995\\u09b0\\u09cd\\u09ae\\u09c0\\u09b0\\u09be \\u0985\\u09b8\\u09b9\\u09af\\u09cb\\u0997\\u09c0\\u0964 \\u0986\\u09ae\\u09bf \\u09a6\\u09c1\\u0987 \\u0998\\u09a3\\u09cd\\u099f\\u09be \\u0985\\u09aa\\u09c7\\u0995\\u09cd\\u09b7\\u09be \\u0995\\u09b0\\u09c7\\u0993 \\u09b8\\u09c7\\u09ac\\u09be \\u09aa\\u09be\\u0987\\u09a8\\u09bf\\u0964\",\n          \"\\u09ac\\u09cd\\u09af\\u09be\\u0982\\u0995\\u09c7\\u09b0 \\u098f\\u099c\\u09c7\\u09a8\\u09cd\\u099f \\u09ac\\u09cd\\u09af\\u09be\\u0982\\u0995\\u09bf\\u0982 \\u0995\\u09bf? \\u098f\\u099f\\u09be \\u0995\\u09bf\\u09ad\\u09be\\u09ac\\u09c7 \\u0995\\u09be\\u099c \\u0995\\u09b0\\u09c7 \\u099c\\u09be\\u09a8\\u09a4\\u09c7 \\u099a\\u09be\\u0987?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY"
      },
      "source": [
        "### 3.1 Preprocessing Data\n",
        "In the next steps we are going to create tokenize the text, create index mapping for words, and also construct a vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb"
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "# Use the minimum between 50000 and the DataFrame length to avoid the error\n",
        "n_samples = min(50000, len(data))\n",
        "data = data.sample(n=n_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KouYEDoNSuCe"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa\n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "\n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "\n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "\n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8352c092-d742-4845-fb82-3aab4903fab1"
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '300.00',\n",
              " 'BPDB',\n",
              " 'Charge-RM50518',\n",
              " 'Direct',\n",
              " 'Grameenphone',\n",
              " 'Ltd-Mycompany_y',\n",
              " 'Payment',\n",
              " 'Tk',\n",
              " 'Translation']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk"
      },
      "source": [
        "### 3.2 Converting Data into Tensors\n",
        "For convenience we would like to convert the data into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk"
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148b27f9-9c4a-4ebd-890f-80c6c09e1e94"
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[189, 385, 591, 69, 245, 26, 578, 149, 295, 25, 442, 389, 145, 107, 202, 580],\n",
              " [464, 346, 462, 604, 589, 228, 276, 70, 515, 534, 141, 378, 112, 203, 605]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr"
      },
      "source": [
        "### 3.3 Padding data\n",
        "In order to train our recurrent neural network later on in the notebook, it is required padding to generate inputs of same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51980e5-f8ad-468a-e7e0-5fff5bc11014"
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0"
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2"
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dok2XcWSuC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13eafc8-e0b1-4638-964e-a7f0efe33fb6"
      },
      "source": [
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([189, 385, 591,  69, 245,  26, 578, 149, 295,  25, 442, 389, 145,\n",
              "        107, 202, 580,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
              " array([464, 346, 462, 604, 589, 228, 276,  70, 515, 534, 141, 378, 112,\n",
              "        203, 605,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0])]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-"
      },
      "source": [
        "### 3.4 Binarization\n",
        "We would like to binarize our target so that we can obtain one-hot encodings as target values. These are easier and more efficient to work with and will be useful when training the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA"
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "sentiments = list(set(data.sentiment.unique()))\n",
        "num_sentiments = len(sentiments)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(sentiments) for emos in data[['sentiment']].values]\n",
        "bin_sentiments = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_sentiments.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa23a5d4-613c-4f61-fbf7-074f8088b95c"
      },
      "source": [
        "target_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "0c669cec-d592-4c84-a20f-4cea38c4d55c"
      },
      "source": [
        "data[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text sentiment  \\\n",
              "56    56  কোম্পানির পে-লেটার সার্ভিস আমার জীবন অনেক সহজ ...  positive   \n",
              "139  139  ব্যাংকের নেট ব্যাংকিং সুবিধা সারাদিন চালু থাকে...  positive   \n",
              "133  133  কোম্পানির ওয়ারেন্টি পলিসি কাগজে-কলমে ভালো কিন...  negative   \n",
              "65    65  কোম্পানির পণ্যের দাম কত? সবগুলোর একটা তালিকা প...   neutral   \n",
              "155  155  কোম্পানির বিক্রয় পরবর্তী সেবা অত্যন্ত নিম্নমা...  negative   \n",
              "38    38  কোম্পানির বিক্রয় পরবর্তী সেবা অত্যন্ত নিম্নমা...  negative   \n",
              "47    47  কোম্পানির সদর দপ্তর কোথায় অবস্থিত? আমি একটি আ...   neutral   \n",
              "6      6  কোম্পানির অফার কি শুধু নতুন গ্রাহকদের জন্য? পু...   neutral   \n",
              "171  171  ব্যাংকের লোন প্রক্রিয়া কি? কি কি ডকুমেন্ট লাগ...   neutral   \n",
              "122  122  কোম্পানির মোবাইল অ্যাপটি ব্যবহার করে আমি খুব স...  positive   \n",
              "\n",
              "     token_size  \n",
              "56           16  \n",
              "139          15  \n",
              "133          12  \n",
              "65           10  \n",
              "155          12  \n",
              "38           11  \n",
              "47           11  \n",
              "6            13  \n",
              "171          10  \n",
              "122          16  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad70a7dd-4424-485e-b4dd-53d9e8f7d8c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>কোম্পানির পে-লেটার সার্ভিস আমার জীবন অনেক সহজ ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>139</td>\n",
              "      <td>ব্যাংকের নেট ব্যাংকিং সুবিধা সারাদিন চালু থাকে...</td>\n",
              "      <td>positive</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>133</td>\n",
              "      <td>কোম্পানির ওয়ারেন্টি পলিসি কাগজে-কলমে ভালো কিন...</td>\n",
              "      <td>negative</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>কোম্পানির পণ্যের দাম কত? সবগুলোর একটা তালিকা প...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>155</td>\n",
              "      <td>কোম্পানির বিক্রয় পরবর্তী সেবা অত্যন্ত নিম্নমা...</td>\n",
              "      <td>negative</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>কোম্পানির বিক্রয় পরবর্তী সেবা অত্যন্ত নিম্নমা...</td>\n",
              "      <td>negative</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>কোম্পানির সদর দপ্তর কোথায় অবস্থিত? আমি একটি আ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>কোম্পানির অফার কি শুধু নতুন গ্রাহকদের জন্য? পু...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>171</td>\n",
              "      <td>ব্যাংকের লোন প্রক্রিয়া কি? কি কি ডকুমেন্ট লাগ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>কোম্পানির মোবাইল অ্যাপটি ব্যবহার করে আমি খুব স...</td>\n",
              "      <td>positive</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad70a7dd-4424-485e-b4dd-53d9e8f7d8c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad70a7dd-4424-485e-b4dd-53d9e8f7d8c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad70a7dd-4424-485e-b4dd-53d9e8f7d8c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-05b53250-1bc8-453d-a005-8980cc5b342a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05b53250-1bc8-453d-a005-8980cc5b342a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-05b53250-1bc8-453d-a005-8980cc5b342a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data[0:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 6,\n        \"max\": 171,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          171,\n          139,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u09ac\\u09cd\\u09af\\u09be\\u0982\\u0995\\u09c7\\u09b0 \\u09b2\\u09cb\\u09a8 \\u09aa\\u09cd\\u09b0\\u0995\\u09cd\\u09b0\\u09bf\\u09af\\u09bc\\u09be \\u0995\\u09bf? \\u0995\\u09bf \\u0995\\u09bf \\u09a1\\u0995\\u09c1\\u09ae\\u09c7\\u09a8\\u09cd\\u099f \\u09b2\\u09be\\u0997\\u09ac\\u09c7 \\u099c\\u09be\\u09a8\\u09a4\\u09c7 \\u099a\\u09be\\u0987?\",\n          \"\\u09ac\\u09cd\\u09af\\u09be\\u0982\\u0995\\u09c7\\u09b0 \\u09a8\\u09c7\\u099f \\u09ac\\u09cd\\u09af\\u09be\\u0982\\u0995\\u09bf\\u0982 \\u09b8\\u09c1\\u09ac\\u09bf\\u09a7\\u09be \\u09b8\\u09be\\u09b0\\u09be\\u09a6\\u09bf\\u09a8 \\u099a\\u09be\\u09b2\\u09c1 \\u09a5\\u09be\\u0995\\u09c7, \\u0986\\u09ae\\u09bf \\u09b0\\u09be\\u09a4\\u09c7\\u0993 \\u09b2\\u09c7\\u09a8\\u09a6\\u09c7\\u09a8 \\u0995\\u09b0\\u09a4\\u09c7 \\u09aa\\u09be\\u09b0\\u09bf? \\u098f\\u099f\\u09be \\u0996\\u09c1\\u09ac\\u0987 \\u09b8\\u09c1\\u09ac\\u09bf\\u09a7\\u09be\\u099c\\u09a8\\u0995\\u0964\",\n          \"\\u0995\\u09cb\\u09ae\\u09cd\\u09aa\\u09be\\u09a8\\u09bf\\u09b0 \\u09ac\\u09bf\\u0995\\u09cd\\u09b0\\u09af\\u09bc \\u09aa\\u09b0\\u09ac\\u09b0\\u09cd\\u09a4\\u09c0 \\u09b8\\u09c7\\u09ac\\u09be \\u0985\\u09a4\\u09cd\\u09af\\u09a8\\u09cd\\u09a4 \\u09a8\\u09bf\\u09ae\\u09cd\\u09a8\\u09ae\\u09be\\u09a8\\u09c7\\u09b0\\u0964 \\u0986\\u09ae\\u09bf \\u098f\\u0996\\u09a8 \\u09aa\\u09b0\\u09cd\\u09af\\u09a8\\u09cd\\u09a4 \\u09b8\\u09ae\\u09be\\u09a7\\u09be\\u09a8 \\u09aa\\u09be\\u0987\\u09a8\\u09bf\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 10,\n        \"max\": 16,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          16,\n          15,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI"
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a40e1f-529b-4046-ab99-548d0ac41413"
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN"
      },
      "source": [
        "sentiment_dict = {0: 'negative', 1: 'neutral', 2: 'positive' }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c11d5722-2d9b-420b-b95c-c0358ee819d8"
      },
      "source": [
        "sentiment_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ"
      },
      "source": [
        "### 3.5 Split data\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd549260-cedd-45ac-ab04-81def9e91f4c"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151, 151, 19, 19, 19, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX"
      },
      "source": [
        "### 3.6 Data Loader\n",
        "We can also laod the data into a data loader, which makes it easy to **manipulate the data**, **create batches**, and apply further **transformations**. In PyTorch we can use the `DataLoader` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX"
      },
      "source": [
        "# ... (previous code) ...\n",
        "\n",
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val) # Original line\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Place the change here:\n",
        "VAL_BUFFER_SIZE = max(VAL_BUFFER_SIZE, BATCH_SIZE)  # Ensure VAL_BUFFER_SIZE is at least equal to BATCH_SIZE\n",
        "\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_sentiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa"
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader\n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc"
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE,\n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE,\n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE,\n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78050fee-2a51-4863-823d-0ba9b9f69edd"
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh"
      },
      "source": [
        "## 4. Model\n",
        "After the data has been preprocessed, transformed and prepared it is now time to construct the model or the so-called computation graph that will be used to train our classification models. We are going to use a gated recurrent neural network (GRU), which is considered a more efficient version of a basic RNN. The figure below shows a high-level overview of the model details.\n",
        "\n",
        "![alt txt](https://github.com/omarsar/nlp_pytorch_tensorflow_notebooks/blob/master/img/gru-model.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi"
      },
      "source": [
        "### 4.1 Constructing the Model\n",
        "Below we construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVXtMhf3SuDj"
      },
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "\n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk"
      },
      "source": [
        "### 4.2 Pretesting model\n",
        "Since eager execution is enabled we can print the output of the model by passing a sample of the dataset and making sure that the dimensions of the outputs are the expected ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl"
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de426f1e-516d-44e0-eee9-cdb17cbb1e1a"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size:  torch.Size([61, 64])\n",
            "torch.Size([64, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp"
      },
      "source": [
        "## 5. Training the Model\n",
        "Now that we have tested the model, it is time to train it. We will define out optimization algorithm, learnin rate, and other necessary information to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp"
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target)\n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "\n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c73812b-41e4-45eb-ccd6-06802ca567a2"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "\n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _\n",
        "\n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "\n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1,\n",
        "                                                             total_loss / TRAIN_N_BATCH,\n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3790\n",
            "Epoch 1 Loss 0.6888 -- Train Acc. 32.0312 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.09551072120666504 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.4237\n",
            "Epoch 2 Loss 0.4261 -- Train Acc. 39.0625 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.09258508682250977 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.4927\n",
            "Epoch 3 Loss 0.4392 -- Train Acc. 35.9375 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.0813910961151123 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.3818\n",
            "Epoch 4 Loss 0.3980 -- Train Acc. 32.0312 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06122136116027832 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.4172\n",
            "Epoch 5 Loss 0.4039 -- Train Acc. 35.9375 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06320905685424805 sec\n",
            "\n",
            "Epoch 6 Batch 0 Val. Loss 0.3977\n",
            "Epoch 6 Loss 0.3802 -- Train Acc. 32.8125 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06337928771972656 sec\n",
            "\n",
            "Epoch 7 Batch 0 Val. Loss 0.3642\n",
            "Epoch 7 Loss 0.3836 -- Train Acc. 33.5938 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06157636642456055 sec\n",
            "\n",
            "Epoch 8 Batch 0 Val. Loss 0.3973\n",
            "Epoch 8 Loss 0.3853 -- Train Acc. 39.8438 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06496977806091309 sec\n",
            "\n",
            "Epoch 9 Batch 0 Val. Loss 0.3718\n",
            "Epoch 9 Loss 0.3702 -- Train Acc. 35.1562 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06292414665222168 sec\n",
            "\n",
            "Epoch 10 Batch 0 Val. Loss 0.3939\n",
            "Epoch 10 Loss 0.3809 -- Train Acc. 35.1562 -- Val Acc. 0.0000\n",
            "Time taken for 1 epoch 0.06331419944763184 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "a1fb8243-0e40-49fa-c614-eccd999a9adb"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(659, 256)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.module.Module.parameters</b><br/>def parameters(recurse: bool=True) -&gt; Iterator[Parameter]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py</a>Return an iterator over module parameters.\n",
              "\n",
              "This is typically passed to an optimizer.\n",
              "\n",
              "Args:\n",
              "    recurse (bool): if True, then yields parameters of this module\n",
              "        and all submodules. Otherwise, yields only parameters that\n",
              "        are direct members of this module.\n",
              "\n",
              "Yields:\n",
              "    Parameter: module parameter\n",
              "\n",
              "Example::\n",
              "\n",
              "    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)\n",
              "    &gt;&gt;&gt; for param in model.parameters():\n",
              "    &gt;&gt;&gt;     print(type(param), param.size())\n",
              "    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L,)\n",
              "    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L, 1L, 5L, 5L)</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2608);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n",
        "Now we will evaluate the model with the holdout dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a271361b-4a6a-42a6-fa72-7951f93d81c8"
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cuda\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):\n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)\n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "\n",
        "    # Change here: accumulate accuracy as a tensor\n",
        "    test_accuracy += batch_accuracy.item()\n",
        "\n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "\n",
        "    all_predictions.append(predictions)\n",
        "\n",
        "# Change here: Convert test_accuracy to a tensor before calling cpu(), detach(), and numpy()\n",
        "print(\"Test Accuracy: \", torch.tensor(test_accuracy).cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-0c6491293059>:22: RuntimeWarning: invalid value encountered in divide\n",
            "  print(\"Test Accuracy: \", torch.tensor(test_accuracy).cpu().detach().numpy() / TEST_N_BATCH)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz"
      },
      "source": [
        "### 6.1 Confusion Matrix\n",
        "The test accuracy alone is not an interesting performance metric in this case. Let's plot a confusion matrix to get a drilled down view of how the model is performing with regards to each emotion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM"
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "5cc1d9fd-de58-4f87-8f81-6f5f21e4c1a6"
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "\n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "sentiment_dict = {0: 'negative', 1: 'neutral', 2: 'positive' }\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"sentiment\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"sentiment\"])\n",
        "\n",
        "model_test_result.sentiment = model_test_result.sentiment.map(lambda x: sentiment_dict[int(float(x))])\n",
        "test.sentiment = test.sentiment.map(lambda x: sentiment_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.sentiment, test.sentiment );"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Classification report\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-c4d437a6e75b>:28: RuntimeWarning: Mean of empty slice.\n",
            "  (pair[0], pair[1].mean()) for pair in zip(\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-7d2aaf2c9339>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentiment_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_test_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-c4d437a6e75b>\u001b[0m in \u001b[0;36mevaluate_class\u001b[0;34m(cls, predictions, target, target2, silent)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Default Classification report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# print if target2 was provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weighted avg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:>{width}s} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" {:>9}\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8dx7Ay3lXvs",
        "outputId": "105af3b2-3c89-4c78-bdd6-408ec0ba99db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-ebf5a705523b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Calculate average accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTCznkUGSuD3"
      },
      "source": [
        "## Final Words\n",
        "You have learned how to perform neural-based emotion recognition using RNNs. There are many things you can do after you have completed this tutorial. You can attempt the exercises outlined in the \"Outline\" section of this notebook. You can also try other types of neural architectures such as LSTMs, Bi-LSTMS, attentions models, and CNNs. In addition, you can also store the models and conduct transfer learning to other emotion-related tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbkPHgFSuD3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLfZrr2oSuD4"
      },
      "source": [
        "## References\n",
        "- [Deep Learning for NLP](https://docs.google.com/presentation/d/1cf2H1qMvP1rdKUF5000ifOIRv1_b0bvj0ZTVL7-RaVE/edit?usp=sharing)\n",
        "- [PyTorch Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
        "- [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0)\n",
        "- [Building RNNs is Fun with PyTorch and Google Colab](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79?source=collection_home---4------2---------------------)\n",
        "- [Deep Learning for NLP: An Overview of Recent Trends](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d)"
      ]
    }
  ]
}